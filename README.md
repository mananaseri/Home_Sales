# Home_Sales

# Requirements :
Apache Spark
Python (with PySpark)
Jupyter Notebook or Google Colab (optional)

# How to Run 
1) clone the repository in your computer
2) download the module 22
3) open google colab
4) run the data and open github there to be connceted to github
5) publish in git hub

We are using SparkSQL for analyzing home sales data.

# overview 

1) Calculate the average price for different criteria for each year
2) cache the the temporary table home_sales
3) build Partition the data by the "date_built" field.
4) read it with parquet
5) and then get average price of a home per "view" rating



